#!/usr/bin/env python2.7
description="""
                        -------
-----------------------| SAAB+ |-----------------------
                        -------
           Annotation of BCR repertoires with
                 Structural Information

                    Version: 1.1.0

        SAAB+ developed by Kovaltsuk et al., 2019.

                BSD 3-Clause License
 Copyright (c) 2019, Oxford Protein Informatics Group (OPIG)
                All rights reserved.

         For feedback, questions and bug reports
         please contact <opig@stats.ox.ac.uk> or
                     <kovaltsu@stats.ox.ac.uk>              

                        --------
-----------------------| INPUTS |----------------------
                        --------
     SAAB_PLUS takes a .fasta file as the input e.g.

    >blah1
    SLRLSCAASGFTFSGHWMYWVRQAPGKGLVWVARINND.....
    >blah2
    SLRLSCAASGFTFRSYWMSWVRQAPGRGLEWIARIND......

            SAAB+ supports heavy and light chain 
                BCR repertoire analysis

                       ---------
----------------------| OUTPUTS |----------------------
                       ---------
     SAAB+ outputs a gzip'ed tab-delimited (DataFrame) 
         text file with Structural Annotation

          DataFrame columns are:

            Protein_Seq - Full antibody amino acid sequences
   CDR-{H3,L3}_template - FREAD PDB templates
{H1,L1}_Canonical_Class - SCALOP predicted CDR-H1 canonical class
{H2,L2}_Canonical_Class - SCALOP predicted CDR-H2 canonical class
             Redundancy - Number of Proiten_Seq copies in the
                          input fasta file
     Framework_template - PDB template used in CDR-{H3, L3} 
                          structure prediction
   CDR-{H3,L3}_sequence - Sequence of CDR-{H3,L3} loop
                    ESS - FREAD score for the predicted 
                          CDR-{H3,L3} structure
             Annotation - Sequences, whose CDR-{H3,L3} structure
                          prediction scores were above 
                          the quality threshold
               Clusters - CDR-{H3,L3} clusters (0.6A threshold)
-------------------------------------------------------
"""

import logging
logging.basicConfig(filename='saab_plus.log', level=logging.INFO,
                     format="%(asctime)-15s %(levelname)s %(message)s",
                     datefmt='%Y-%m-%d %H:%M:%S')

import pandas as pd
import os, sys, textwrap
from argparse import ArgumentParser, RawDescriptionHelpFormatter
from saab_plus.aboss_utils.run_ANARCI_parsing import Main
from Bio import SeqIO
from collections import Counter
from saab_plus.RunSAAB import RunSaab
from saab_plus.code.apply_ess_cutoff import ApplyESS
from saab_plus.run_diagnostics import Diagnostics 

class Annotation(object):
    """
    Annotation of BCR repertoires with structural information
    """
    def __init__(self, arguments):
        self.filename = arguments["filename"]
        self.ncores = arguments["ncores"]
        self.species = arguments["species"]
        self.chain = arguments["chain"]
        self.output_name = arguments["output_name"]
        self.output_dir = arguments["output_dir"]
        print "SAAB plus log is found in saab_plus.log"
        
        if not self.pass_diagnostics():
            raise AssertionError("""
            Some saab_plus packages are missing
            Please python run_diagnostics.py to see details
                                 """)

    def check_diagnostics_log(self):
        """
        Function that checks if any ERRORs
        were recorded in diagnostics.log
        """
        errors = ["ERROR" in line for line in open("diagnostics.log","r") ]
        if not any(errors) and len(errors) > 0:
            return True
        return False

    def pass_diagnostics(self):
        """
        Deleting existing diagnostics.log file.
        Next, running Diagnostics() and 
        checking for any errors
        """
        if os.path.isfile( "diagnostics.log" ):
            os.remove( "diagnostics.log" )
        diagnostics = Diagnostics()
        diagnostics()
        if not os.path.isfile( "diagnostics.log" ):
            raise AssertionError( "diagnostics.log was not created!?" )
        return self.check_diagnostics_log()

    def unique_aa(self):
        "reading fasta and converting to python dict"
        records = SeqIO.parse( self.filename, 'fasta' )
        return Counter( str( rec.seq ) for rec in records )

    def convert_fasta_to_frame(self):
        """
        Converting fasta file to pandas dataframe
        If your input is not fasta file,
        please modify this method accordingly.
        ----------
        Parameters
            self.unique_aa() - converts FASTA file to dictionary.
                               Key is the unique antibody sequence and
                               Value is the number of repeats
        ----------
        Returns
            self.gzipped -   GZipped DataFrame that is turned into
                             an iterator later on for SAAB+ analysis
        """
        df = pd.DataFrame( self.unique_aa().items(),
                                            columns = [ "Protein_Seq", "Redundancy" ])
        self.gziped = "{0}_df.txt.gz".format(self.filename)
        df.to_csv( self.gziped, sep = "\t", compression = "gzip" )
        return self

    def clean_intermediate(self):
        logging.info("\tRemoving intermediate: {0}".format( self.gziped ) )
        os.remove( self.gziped ) 

    def run(self):
        # Starting anarci parsing
        print "\n\tInitiating anarci parsing" 
        logging.info("\tStarting ANARCI parsing\n")
        anarci_parsing = Main( input_file = self.gziped, 
                               ncpu = self.ncores, 
                               chain = self.chain, 
                               species = self.species, 
                               output_dir = ".", 
                               output_name = "anarci_parsed.txt") 
        anarci_parsing.run()
        print "\n\tanarci parsing is done\n"
        logging.info("\tANARCI parsing is finished")
        self.clean_intermediate()

        # Starting SAAB running
        anarci_gzip_file = "anarci_parsed.txt.gz"
        if not os.path.isfile( anarci_gzip_file ):
            logging.error("anarci parsed txt file is not found: {0}".format( anarci_gzip_dir ))
            raise AssertionError( "File is not found: ", anarci_gzip_file )

        # Running SAAB+
        print "\tInitiating SAAB plus"
        logging.info("\tStarting SAAB plus pipeline\n")
        saab_instance = RunSaab( anarci_gzip_file,
                                 self.ncores,
                                 self.output_name, 
                                 self.output_dir,
                                 self.chain) 

        saab_instance.initiate_SAAB()
        os.remove( anarci_gzip_file )

        logging.info("\tSAAB+ is finished")
        logging.info("\tApplying quality filters")

        # Quality filters
        apply_ess_instance = ApplyESS( os.path.join( self.output_dir, self.output_name + ".gz" ), self.chain )
        apply_ess_instance.adding_pdb_length.apply_ess()

        logging.info("\tFormating Canonical Classes")
        apply_ess_instance.expanding_canonical_class_dict()
       
        logging.info("\tApplying clustering")
        apply_ess_instance.clustering().save()


        logging.info("\touput_file is: {0}".format( os.path.join( self.output_dir, self.output_name+".gz" )))
        logging.info("\n\n\t\tDONE!\n\n")
        print "\n\tDone!\n"

def initArgParser():
    parser = ArgumentParser(description = textwrap.dedent(description),
                            formatter_class=RawDescriptionHelpFormatter)
    group = parser.add_argument_group('Argument for BCR repertoire annotation')
    group.add_argument('-f', action='store', dest='filename', default=False,
                        help="""FASTA file to be analysed.
                        Only amino acid sequences are accepted""")
    group.add_argument('-s', action='store', dest='species', default="human",
                        help="Species information. Default: human",
                        choices= ["human", "mouse", "rhesus", "alpaca"])
    group.add_argument('-n', action='store', dest='ncores', default=4, type=int,
                        help="Number of CPU cores to use")
    group.add_argument("-c", action="store", dest="chain", default="H",
                        help="Antibody chain information. Light chain being implemented",
                        choices=["H", "L"])
    group.add_argument("-o", action="store", dest="output_name", default="output.txt",
                        help="Output filename, Default is output_name.txt")
    group.add_argument("-d", action="store", dest="output_dir", default=".",
                        help="output directory, Default is current working directory")
    return parser

def printStatus(args):
    print "      FILE: {0}".format(args.filename)
    print "     CORES: {0}".format(args.ncores)
    print "  ORGANISM: {0}".format(args.species)
    print "     CHAIN: {0}".format(args.chain)
    print "OutputName: {0}".format(args.output_name)
    print " OutputDir: {0}".format(args.output_dir)

    logging.info("\t\tInitiating structural annotation pipeline")
    logging.info("\t      FILE: {0}".format(args.filename))
    logging.info("\t     CORES: {0}".format(args.ncores))
    logging.info("\t  ORGANISM: {0}".format(args.species))
    logging.info("\t     CHAIN: {0}".format(args.chain))
    logging.info("\tOutputName: {0}".format(args.output_name))
    logging.info("\t OutputDir: {0}".format(args.output_dir))

    return vars(args)

if __name__ == "__main__":

    parser = initArgParser()
    args = parser.parse_args()

    if len(sys.argv) < 2:
        parser.print_help()
        sys.exit(1)

    if not args.filename:
        raise AssertionError("Filename was not specified, exiting!!!")

    if not args.species:
        raise AssertionError("Species was not selected")

    arguments = printStatus(args)
    STUDY = Annotation(arguments)
    STUDY.convert_fasta_to_frame().run()

